{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training Trajectory Correction LSTM",
   "id": "d44d23b998f00aea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f9c25344a65fa8a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T23:32:18.097680Z",
     "start_time": "2025-04-01T23:32:17.321360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from constants.filepath import PROJECT_PATH\n",
    "\n",
    "plt.close('all')"
   ],
   "id": "36974a6bbe5cabd2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T23:32:18.296679Z",
     "start_time": "2025-04-01T23:32:18.294131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mps_device = torch.device(\"mps\")\n",
    "\n",
    "training_folderpath = os.path.join(PROJECT_PATH, 'dataset/LSTM_training')\n",
    "validation_folderpath = os.path.join(PROJECT_PATH, 'dataset/LSTM_validation')\n",
    "testing_folderpath = os.path.join(PROJECT_PATH, 'dataset/LSTM_testing')\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 600  # For inline display in the notebook\n",
    "plt.rcParams['savefig.dpi'] = 600 # For saving figures to files"
   ],
   "id": "3b733aa224496c10",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T23:32:19.690567Z",
     "start_time": "2025-04-01T23:32:19.683308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(data_path):\n",
    "    data_files = sorted([os.path.join(data_path, f) for f in os.listdir(data_path) if f.endswith('.npz')])\n",
    "    sequences = []\n",
    "    for file in data_files:\n",
    "        \n",
    "        command = torch.tensor(data['command_data'], dtype=torch.float32)\n",
    "        analytical = torch.tensor(data['analytical_data'], dtype=torch.float32)\n",
    "        residuals = torch.tensor(data['residuals'], dtype=torch.float32)\n",
    "\n",
    "        # Stack command and analytical data as input features\n",
    "        input_seq = torch.stack((command, analytical), dim=1)\n",
    "        sequences.append((input_seq, residuals))\n",
    "    return sequences\n",
    "\n",
    "class FlowDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "        self.lengths = [len(seq) for seq in sequences]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.lengths[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, lengths = zip(*batch)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    return padded_sequences, lengths\n",
    "\n",
    "class ResidualLSTM(torch.nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=128, output_dim=1, num_layers=2):\n",
    "        super(ResidualLSTM, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ],
   "id": "38d06b7481b8fc8c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T23:32:21.332876Z",
     "start_time": "2025-04-01T23:32:21.196676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "train_sequences = load_flows(training_folderpath)\n",
    "val_sequences = load_flows(validation_folderpath)\n",
    "train_dataset = FlowDataset(train_sequences)\n",
    "val_dataset = FlowDataset(val_sequences)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ],
   "id": "232597cef1c90d92",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'residuals is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Load the data\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m train_sequences \u001B[38;5;241m=\u001B[39m \u001B[43mload_flows\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_folderpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m val_sequences \u001B[38;5;241m=\u001B[39m load_flows(validation_folderpath)\n\u001B[1;32m      4\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m FlowDataset(train_sequences)\n",
      "Cell \u001B[0;32mIn[3], line 5\u001B[0m, in \u001B[0;36mload_flows\u001B[0;34m(data_path)\u001B[0m\n\u001B[1;32m      3\u001B[0m sequences \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m flow_files:\n\u001B[0;32m----> 5\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresiduals\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m      6\u001B[0m     sequences\u001B[38;5;241m.\u001B[39mappend(torch\u001B[38;5;241m.\u001B[39mtensor(data, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32))\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sequences\n",
      "File \u001B[0;32m~/miniconda3/envs/pycharm-env/lib/python3.11/site-packages/numpy/lib/npyio.py:263\u001B[0m, in \u001B[0;36mNpzFile.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mzip\u001B[38;5;241m.\u001B[39mread(key)\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a file in the archive\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'residuals is not a file in the archive'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training setup\n",
    "model = ResidualLSTM().to(mps_device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 50"
   ],
   "id": "c2a17534a8e697d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch, lengths in train_loader:\n",
    "        batch = batch.to(mps_device)\n",
    "        lengths = lengths.to(mps_device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch, lengths)\n",
    "        loss = criterion(outputs.squeeze(-1), batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader)}\")"
   ],
   "id": "f042df2ed5be7f82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'lstm_residual_model.pth')\n",
    "\n",
    "print(\"Training complete!\")"
   ],
   "id": "bd5adc34563023c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "40155a724b4c8381",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2a0b7973b616aa34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test",
   "id": "fcd5d07863766eda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model = ResidualModel([2, 512, 512, 512, 128, 1]).to('cuda:1')\n",
    "model = ResidualModel([2, 512, 512, 512, 128, 1]).to('mps')\n",
    "\n",
    "state_dict = torch.load('trajectory_correction_DNN_v0_blastoise_ultimate.pth')\n",
    "model.load_state_dict(state_dict)"
   ],
   "id": "6f2700bbfa573be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example: Run model inference (optional, based on your needs)\n",
    "model.eval()\n",
    "\n",
    "##%%\n",
    "test_residuals = np.load(os.path.join(PROJECT_PATH, 'model_data', 'test_residuals.npz'))['residuals']\n",
    "test_command = np.load(os.path.join(PROJECT_PATH, 'model_data', 'test_command_data.npz'))['command_data']\n",
    "test_analytical = np.load(os.path.join(PROJECT_PATH, 'model_data', 'test_analytical_data.npz'))['analytical_data']\n",
    "\n",
    "test_combined = np.stack((test_command, test_analytical), axis=1)\n",
    "test_input = torch.tensor(test_combined, dtype=torch.float32, device=mps_device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(test_input) * 1e-9\n",
    "    test_result = (output).cpu().numpy().reshape(-1)\n",
    "\n",
    "test_sim = test_residuals + test_analytical\n",
    "\n",
    "test_t = np.arange(test_command.shape[0])   \n",
    "plt.figure()\n",
    "plt.plot(test_t, test_command / 1e9, label='Input', color='black', linestyle='--')\n",
    "# plt.plot(test_accel.ts, test_accel.sim_Q_out, label = 'Simulated Data', color = 'red')\n",
    "plt.plot(test_t, test_analytical / 1e9, label = 'Analytical Data', color = 'blue')\n",
    "plt.plot(test_t, test_result, label='Residual', color='magenta')\n",
    "plt.plot(test_t, (test_analytical / 1e9) + test_result, label='Total', color='green')\n",
    "plt.plot(test_t, test_sim / 1e9, label='GT Total', color='r')\n",
    "plt.legend()\n",
    "plt.subplots_adjust(right=0.8)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.85))\n",
    "# plt.savefig('slides/flowrate_altogether', bbox_inches='tight')"
   ],
   "id": "97dc23260b434f65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "plt.plot(test_t, test_command / 1e9, label='Input', color='black', linestyle='--')\n",
    "plt.plot(test_t, test_sim / 1e9, label='Sim', color='r')\n",
    "plt.ylabel('Flow rate [m^3/s]')\n",
    "plt.legend()\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.90))\n",
    "# plt.savefig('slides/flowrate_sim', bbox_inches='tight')"
   ],
   "id": "72428ee60e491686",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "plt.plot(test_t, test_command / 1e9, label='Input', color='black', linestyle='--')\n",
    "plt.plot(test_t, (test_analytical / 1e9) + test_result, label='DNN + Prior', color='green')\n",
    "plt.ylabel('Flow rate [m^3/s]')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.90))\n",
    "# plt.savefig('slides/flowrate_dnn_prior', bbox_inches='tight')"
   ],
   "id": "833784edc1439a81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "plt.plot(test_t, test_command / 1e9, label='Input', color='black', linestyle='--')\n",
    "plt.plot(test_t, (test_analytical / 1e9), label='Prior', color='blue')\n",
    "plt.ylabel('Flow rate [m^3/s]')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.90))\n",
    "# plt.savefig('slides/flowrate_prior', bbox_inches='tight')"
   ],
   "id": "28005700fce5ac19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "# plt.plot(test_t, test_command / 1e9, label='Input', color='black', linestyle='--')\n",
    "prior_error = np.sqrt(np.mean(((test_sim / 1e9) - (test_analytical / 1e9))**2))\n",
    "dnn_prior_error = np.sqrt(np.mean(((test_sim / 1e9) - ((test_analytical / 1e9) + test_result))**2))\n",
    "\n",
    "print('Prior Error:', prior_error)\n",
    "print(\"DNN + Prior Error:\", dnn_prior_error)\n",
    "\n",
    "plt.plot(test_t, (test_sim / 1e9) - (test_analytical / 1e9), label='Prior', color='blue')\n",
    "\n",
    "plt.ylabel('Flow rate [m^3/s]')\n",
    "plt.legend()\n",
    "# plt.savefig('slides/error_prior')"
   ],
   "id": "e22529740e7eab02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "# plt.plot(test_t, test_command / 1e9, label='Input', color='black', linestyle='--')\n",
    "plt.plot(test_t, (test_sim / 1e9) - ((test_analytical / 1e9) + test_result), label='DNN + Prior', color='green')\n",
    "plt.ylabel('Flow rate a[m^3/s]')\n",
    "plt.legend()\n",
    "# plt.savefig('slides/error_dnn_prior')"
   ],
   "id": "66d531f3bdddb4ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(test_t, (test_sim / 1e9) - (test_analytical / 1e9), label='Prior', color='blue')\n",
    "plt.plot(test_t, (test_sim / 1e9) - ((test_analytical / 1e9) + test_result), label='DNN + Prior', color='green')\n",
    "plt.ylabel('Flow rate [m^3/s]')\n",
    "plt.legend()\n",
    "# plt.savefig('slides/error_both')"
   ],
   "id": "bfe48682c0e2c61b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "# plt.plot(test_t, test_command / 1e9, label='Input', color='black', linestyle='--')\n",
    "plt.plot(test_t, (test_sim / 1e9) - (test_sim / 1e9), label='Zero', color='black')\n",
    "plt.ylabel('Flow rate a[m^3/s]')\n",
    "plt.legend()"
   ],
   "id": "1c824267aa1c70ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# torch.save(model.state_dict(), 'trajectory_correction_DNN_v0_blastoise_ultimate.pth')\n",
   "id": "a065ec5db6d51a26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2119abeb2d4fc663",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
