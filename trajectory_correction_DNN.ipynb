{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Trajectory Corrector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from glob import glob\n",
    "from flow_predictor import flow_predictor\n",
    "from tqdm import tqdm\n",
    "from pathgen import training_twosteps\n",
    "\n",
    "mps_device = torch.device(\"cpu\")\n",
    "\n",
    "plt.close('all')\n",
    "from constants.filepath import PROJECT_PATH\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mLoading data...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [04:04<00:00,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mFinished loading data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "location = os.path.join(PROJECT_PATH, 'data', 'sim_samples')\n",
    "workspace_list = glob(os.path.join(location,'*.npz'))\n",
    "\n",
    "residuals = []\n",
    "analytical_data = []\n",
    "command_data = []\n",
    "\n",
    "\n",
    "# print loading data in red text\n",
    "print(\"\\033[91mLoading data...\\033[0m\")\n",
    "for file in tqdm(workspace_list):\n",
    "    saved_data = np.load(file)\n",
    "    Q_out_sim, Q_com_sim, P_p_sim, t_sim = saved_data['Qo_x'], saved_data['Qcom_x'], saved_data['Pp_x'], saved_data['time']\n",
    "    W_com_sim = np.ones(np.shape(t_sim)) * 0.0029\n",
    "    t_vbn, W_com_vbn, Q_com_vbn, Q_out_vbn = flow_predictor(t_sim, Q_com_sim, W_com_sim)\n",
    "    residuals.append(np.interp(t_vbn[t_vbn > 0.2], t_sim, Q_out_sim) - Q_out_vbn[t_vbn > 0.2])\n",
    "    analytical_data.append(Q_out_vbn[t_vbn > 0.2])\n",
    "    command_data.append(Q_com_vbn[t_vbn > 0.2])\n",
    "residuals = np.concatenate(residuals) * 1e9\n",
    "analytical_data = np.concatenate(analytical_data) * 1e9\n",
    "command_data = np.concatenate(command_data) * 1e9\n",
    "# print finished loading data in green text\n",
    "print(\"\\033[92mFinished loading data.\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.stack((command_data, analytical_data), axis=1)\n",
    "# input_features = torch.tensor(analytical_data, dtype=torch.float32, device=mps_device).view(-1, 1)\n",
    "input_features = torch.tensor(input_data, dtype=torch.float32, device=mps_device)\n",
    "target_residuals = torch.tensor(residuals, dtype=torch.float32, device=mps_device).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualModel(torch.nn.Module):\n",
    "    def __init__(self, fc_dim_list = [2, 64, 512, 1024, 512, 64, 1]):\n",
    "        super(ResidualModel, self).__init__()\n",
    "        # self.fc1 = torch.nn.Linear(2, 64)  # Input layer\n",
    "        # self.fc2 = torch.nn.Linear(64, 256)  # Hidden layer\n",
    "        # self.fc3 = torch.nn.Linear(256, 64)  # Output layer\n",
    "        # self.fc4 = torch.nn.Linear(64, 1)  # Output layer\n",
    "        \n",
    "        self.sequence = []\n",
    "        for i in range(1,len(fc_dim_list)):\n",
    "            self.sequence.append(torch.nn.Linear(fc_dim_list[i-1], fc_dim_list[i]))\n",
    "            if i < len(fc_dim_list)-1:\n",
    "                self.sequence.append(torch.nn.ReLU())\n",
    "        self.sequence = torch.nn.Sequential(*self.sequence)\n",
    "\n",
    "        # self.fc1 = torch.nn.Linear(2, 64)  # Input layer\n",
    "        # self.fc2 = torch.nn.Linear(64, 512)  # Hidden layer\n",
    "        # self.fc3 = torch.nn.Linear(512, 1024)  # Hidden layer\n",
    "        # self.fc4 = torch.nn.Linear(1024, 512)  # Output layer\n",
    "        # self.fc5 = torch.nn.Linear(512, 64)  # Output layer\n",
    "        # self.fc6 = torch.nn.Linear(64, 1)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequence(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/500 [04:52<4:00:22, 29.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/500], Loss: 1.2481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 20/500 [09:41<3:48:00, 28.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/500], Loss: 1.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 30/500 [14:30<3:49:34, 29.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/500], Loss: 1.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 32/500 [15:30<3:51:33, 29.69s/it]"
     ]
    }
   ],
   "source": [
    "model = ResidualModel([2, 512, 1])\n",
    "model.to(mps_device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 500\n",
    "model.train()\n",
    "\n",
    "print(\"Training model...\")\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # Forward pass\n",
    "    predictions = model(input_features)\n",
    "    loss = criterion(predictions, target_residuals)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Run model inference (optional, based on your needs)\n",
    "model.eval()\n",
    "\n",
    "#%%\n",
    "\n",
    "test = training_twosteps(flowrate_magnitudes = [[0.75, 0.001], [0.2, 0.001], [0.48, 0.001]],\n",
    "                         flowrate_times = [[0.0001, 8], [15, 20], [22, 33]],\n",
    "                         beadwidth_magnitudes = [[]],\n",
    "                         beadwidth_times = [[]],\n",
    "                         dt = 0.001,\n",
    "                         tmax=40)\n",
    "test_t_input, test_Q_input, test_W_input = test.pathgen()\n",
    "test_t, test_W, test_Q_com, test_Q_out = flow_predictor(test_t_input, test_Q_input, test_W_input)\n",
    "\n",
    "test_analytical = test_Q_out * 1e9\n",
    "test_command = test_Q_com * 1e9\n",
    "test_combined = np.stack((test_command, test_analytical), axis=1)\n",
    "test_input = torch.tensor(test_combined, dtype=torch.float32, device=mps_device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(test_input) * 1e-9\n",
    "    test_result = (output).cpu().numpy().reshape(-1)\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(test_t, test_Q_com, label='Input', color='black', linestyle='--')\n",
    "# plt.plot(test_accel.ts, test_accel.sim_Q_out, label = 'Simulated Data', color = 'red')\n",
    "plt.plot(test_t, test_Q_out, label = 'Analytical Data', color = 'blue')\n",
    "plt.plot(test_t, test_result, label='Residual', color='magenta')\n",
    "plt.plot(test_t, test_Q_out + test_result, label='Total', color='green')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'trajectory_correction_DNN_v0.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vbn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
